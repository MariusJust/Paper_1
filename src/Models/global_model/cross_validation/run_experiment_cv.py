import os
import pandas as pd
import numpy as np
import tensorflow as tf
import random
import warnings
from models.model_functions.helper_functions import Prepare, load_data
from models import MultivariateModelGlobal as Model
from panelsplit.cross_validation import PanelSplit
from panelsplit.plot import plot_splits


warnings.filterwarnings("ignore")
os.environ['PYTHONHASHSEED'] = str(0)
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # 0=all,1=info,2=warning,3=error
tf.get_logger().setLevel('ERROR')

class MainLoop:
    """
    Class implementing the static neural network model.
    """

    def __init__(self, node_index, nodes_list, no_inits, seed_value, lr, min_delta, patience, verbose, dropout, n_splits, formulation, cv_approach, penalty, n_countries, time_periods):

        #load data
        growth, precip, temp, panel_split = load_data('CV', n_splits, formulation, n_countries, time_periods)
    
        # List to save model instances and performance metrics from each initialization.
        self.models_tmp =  np.zeros(no_inits, dtype=object)
        self.cv_errors_inits = np.zeros(no_inits)
        self.node_index = node_index
        self.nodes_list = nodes_list
        self.no_inits = no_inits
        self.seed_value = seed_value
        self.lr = lr
        self.min_delta = min_delta
        self.patience = patience
        self.verbose = verbose
        self.dropout = dropout
        self.n_splits = n_splits
        self.formulation = formulation
        self.growth = growth
        self.temp = temp
        self.precip = precip
        self.panel_split = panel_split
        self.cv_approach = cv_approach
        self.penalty = penalty
    
        self.factory = Model(
                nodes=None,     # we’ll pass nodes later
                x_train=None,   # factory only builds, doesn’t store data
                y_train=None,
                dropout=self.dropout,
                formulation=self.formulation,
                penalty=self.penalty
            )
      
    def run_experiment(self):   
        # Loop over initializations
        for j in range(self.no_inits):
            self.current_seed = self.seed_value + j  # update seed
            # iterate over each split generated by PanelSplit
            if self.cv_approach=='full':
                self.cv_full(j)
                # 1. fit on the full dataset and save the fixed effects
                # 2. do cross validation on the training set (ie only the neural network part), and add the fixed effects from 1 when predicting
            elif self.cv_approach=='last_period':
                self.cv_last_period(j)
                # fit on time period 1 to T-1 and save the fixed effect from period T-1
                # do cross validation on the training set (ie only the neural network part), and add the fixed effects from T-1 when predicting
            elif self.cv_approach=='simple': 
                self.cv_simple(j)
                #only do cross validation on the training set (ie only the neural network part)
                # when predicting then calculate the mse as the difference between the prediction and the actual value
            else:
                raise ValueError("cv_approach must be either 'full', 'last_period' or 'simple'")
            
        self.best_init_idx = int(np.argmin(self.cv_errors_inits))
        self.best_cv_error = self.cv_errors_inits[self.best_init_idx]
        #retrain the model on the full dataset using the best initialization
        self.train_on_full_sample()
        
        return self.best_cv_error, self.nodes_list[self.node_index]
            
    def cv_full(self, j):
        # 1. first step is to fit the model on the full dataset
        # call the train function and set all train_idx to True
        train_idx = np.array([True] * len(self.growth['global']))
        
        model_full = self.train_itteration(train_idx)
        self.country_FE = model_full.alpha
        self.time_FE = model_full.beta
        
        # 2. now we can do the cross validation, but only on the neural network part
        errors_j = []  # Store error (MSE) for each split in this initialization
        for train_idx, test_idx in self.panel_split.split():
                
                self.models_tmp[j]=self.train_itteration(train_idx)
                
                self.model_instance = self.models_tmp[j]
                country_FE = self.country_FE
                #choose the time fixed effect that corresponds to the test period
                
                test_int=np.where(test_idx==True)[0][0]
                time_FE = np.array(self.time_FE)[test_int-1]
                
                mse=self.test_itteration(test_idx, country_FE, time_FE)
                
                errors_j.append(mse)
                
            # Average error for this initialization
        self.cv_errors_inits[j] = np.mean(errors_j)
            
        return None
    

    def cv_last_period(self, j):
      
        errors_j = []
        for train_idx, test_idx in self.panel_split.split():
                
                self.models_tmp[j]=self.train_itteration(train_idx)
                
                country_FE = self.models_tmp[j].alpha
                time_FE = np.array(self.models_tmp[j].beta)[-1]
                self.model_instance = self.models_tmp[j]
                
                mse=self.test_itteration(test_idx, country_FE, time_FE)
                
                errors_j.append(mse)
                
            # Average error for this initialization
        self.cv_errors_inits[j] = np.mean(errors_j)
        
        return None

    
    # def cv_simple(self, j):
      
    #     errors_j = []
    #     for train_idx, test_idx in self.panel_split.split():
                
    #             self.models_tmp[j]=self.train_itteration(train_idx)
                
    #             country_FE = self.models_tmp[j].alpha
    #             time_FE = np.array(self.models_tmp[j].beta)[-1]
    #             self.model_instance = self.models_tmp[j]
                
    #             mse=self.test_itteration(test_idx, country_FE, time_FE)
                
    #             errors_j.append(mse)
                
    #         # Average error for this initialization
    #     self.cv_errors_inits[j] = np.mean(errors_j)
        
    #     return None    
    
    
    
    

    def train_itteration(self, train_idx):

        
        
            # Prepare training and test sets
            growth_train = {'global': self.growth['global'].loc[train_idx]}

            # For temperature and precipitation:
            temp_train = {'global': self.temp['global'].loc[train_idx].reset_index(drop=True)}
          
            precip_train = {'global': self.precip['global'].loc[train_idx].reset_index(drop=True)}
         
            x_train = [temp_train, precip_train]
            
            self.factory.nodes   = self.nodes_list[self.node_index]
            self.factory.x_train = x_train
            self.factory.y_train = growth_train
            self.factory.Depth=len(self.factory.nodes)
         
            #  set seeds for reproducibility
            tf.random.set_seed(self.current_seed)
            np.random.default_rng(self.current_seed)
            random.seed(self.current_seed)

            # Initialize and fit the model
    
            model_instance=self.factory.get_model()
            model_instance.fit(lr=self.lr, min_delta=self.min_delta, patience=self.patience, verbose=self.verbose)
           
            return model_instance
        
    def test_itteration(self, test_idx, country_FE, time_FE):
       # Prepare training and test sets
            growth_test = np.array(self.growth['global'].loc[test_idx].reset_index(drop=True)).reshape(1, 1, -1, 1)
            temp_test = np.array(self.temp['global'].loc[test_idx].reset_index(drop=True)).reshape((1, 1, -1, 1))

            precip_test = np.array(self.precip['global'].loc[test_idx].reset_index(drop=True)).reshape((1, 1, -1, 1))
            x_test = tf.concat([temp_test, precip_test], axis=3)
            
            
            if country_FE is not None:
                full_country_FE = np.concatenate([[0.], np.array(country_FE)[0]], axis=0)  

                full_country_FE=tf.reshape(full_country_FE, (1, 1, -1, 1))    
        
                time_FE=tf.reshape(time_FE, (1, 1, 1,1))
                
                preds = np.reshape(self.model_instance.model_pred.predict([x_test, full_country_FE, time_FE]), (-1, 1), order='F')
            else:
                preds= np.reshape(self.model_instance.model_visual.predict([x_test]), (-1, 1), order='F')
                
            
            mse = np.nanmean((preds - growth_test) ** 2)
            return mse
    
    def train_on_full_sample(self):

           
            # Compute the best seed based on the best initialization index.
            best_seed = self.best_init_idx

            # Clear session and reinitialize seeds for reproducibility using best_seed
            
            tf.random.set_seed(best_seed)
            np.random.default_rng(best_seed)
            random.seed(best_seed)

            x_train = [self.temp, self.precip]
            growth_train = {'global': self.growth['global']}
            
            self.factory.nodes   = self.nodes_list[self.node_index]
            self.factory.x_train = x_train
            self.factory.y_train = growth_train
            self.factory.Depth=len(self.factory.nodes)
                
            model_full = self.factory.get_model()
            # Train the model on the full dataset.
            model_full.fit(lr=self.lr, min_delta=self.min_delta, patience=self.patience, verbose=self.verbose)

            # Save the final model weights.
            model_full.save_params('results/Model Parameters/CV/' + str(self.nodes_list[self.node_index]) + '.weights.h5')

            return None
