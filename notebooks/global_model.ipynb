{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "406482a6",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; padding-top: 30px; padding-bottom: 10px;\">\n",
    "\n",
    "<h1 style=\"font-size: 2.8em; font-weight: 600; margin-bottom: 0.2em;\">\n",
    "Global Neural Network Model\n",
    "</h1>\n",
    "\n",
    "<p style=\"font-size: 1.2em; color: gray; font-style: italic; margin-top: 0;\">\n",
    "This notebook visualises the main results from the paper.\n",
    "</p>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e103efc",
   "metadata": {},
   "source": [
    "##  1. Loading Packages and Data\n",
    "\n",
    "In this section, we import required libraries, define the model parameters and load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f25113ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-13 15:44:05.666367: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-13 15:44:05.797267: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-13 15:44:05.808782: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-13 15:44:05.820152: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1755099845.835088   40422 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1755099845.841583   40422 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-13 15:44:05.858569: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "create_pred_input() got an unexpected keyword argument 'mean_temp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m mean_precip\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mnanmean(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecipPopWeight\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     31\u001b[0m std_precip\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mnanstd(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecipPopWeight\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m pred_input, T, P\u001b[38;5;241m=\u001b[39m \u001b[43mcreate_pred_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean_temp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean_temp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd_temp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstd_temp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean_precip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean_precip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd_precip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstd_precip\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m#load results from simulations and retrieve best n models\u001b[39;00m\n\u001b[1;32m     37\u001b[0m n_models \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m  \n",
      "\u001b[0;31mTypeError\u001b[0m: create_pred_input() got an unexpected keyword argument 'mean_temp'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "from models.global_model.model_functions.helper_functions.prepare_data import Prepare\n",
    "from utils import create_pred_input\n",
    "from scipy.interpolate import griddata\n",
    "from models import MultivariateModelGlobal as Model       \n",
    "\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = str(0)\n",
    "\n",
    "#model parameters                    \n",
    "lr = 0.001                      # Learning rate\n",
    "min_delta = 1e-6               # Tolerance for optimization\n",
    "patience = 50                   # Patience for early stopping\n",
    "verbose = 2                     # Verbosity mode for optimization\n",
    "n_countries=196\n",
    "time_periods=63                 #\n",
    "\n",
    "#prepare the data\n",
    "data=pd.read_excel('../data/MainData.xlsx')\n",
    "growth, precip, temp = Prepare(data, n_countries, time_periods)\n",
    "x_train = {0:temp, 1:precip}\n",
    "\n",
    "#summary statics for standardisation\n",
    "mean_temp=np.nanmean(data[\"TempPopWeight\"])\n",
    "std_temp=np.nanstd(data[\"TempPopWeight\"])\n",
    "mean_precip=np.nanmean(data[\"PrecipPopWeight\"])\n",
    "std_precip=np.nanstd(data[\"PrecipPopWeight\"])\n",
    "\n",
    "pred_input, T, P= create_pred_input(mc=False, mean_temp=mean_temp, std_temp=std_temp, mean_precip=mean_precip, std_precip=std_precip)\n",
    "\n",
    "\n",
    "#load results from simulations and retrieve best n models\n",
    "n_models = 10  \n",
    "date_of_run = '2025-06-05'\n",
    "Model_selection='CV'\n",
    "\n",
    "results = dict(np.load(f'../results/metrics/{Model_selection}/{date_of_run}/results.npy', \n",
    "                       allow_pickle=True).item())\n",
    "results={k: v for k,v in results.items() if v is not None}\n",
    "top_models = sorted(results, key=lambda node: results[node])[1:n_models]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41c0781",
   "metadata": {},
   "source": [
    "# 2. Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2c4eb1",
   "metadata": {},
   "source": [
    "## 2.1 Comparing top-n models to Leirvik "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7500e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# --- Build surfaces for each of the top-n models ---------------------\n",
    "model_surfaces = []\n",
    "for idx, node in enumerate(top_models, 1):\n",
    "    \n",
    "    # instantiate and load your model\n",
    "    factory = Model(node, x_train, growth, dropout=0.2, penalty=0)\n",
    "    factory.Depth=len(node)\n",
    "    model=factory.get_model()\n",
    "    weight_file = f'../results/Model Parameters/{Model_selection}/{date_of_run}/{node}.weights.h5'\n",
    "    model.load_params(weight_file)\n",
    "\n",
    "    # fit & predict\n",
    "    model.fit(lr=lr, min_delta=min_delta, patience=patience, verbose=verbose)\n",
    "   \n",
    "    pred_flat = model.model_visual.predict(pred_input).reshape(-1,)\n",
    "    Growth = pred_flat.reshape(T.shape) + 0.017\n",
    "\n",
    "    opacity = 0.3\n",
    "    surf = go.Surface(\n",
    "        x=T, y=P, z=Growth,\n",
    "        colorscale='Cividis',\n",
    "        opacity=0.85,\n",
    "        showscale=False,\n",
    "        name=f'Model {node}'\n",
    "    )\n",
    "    model_surfaces.append(surf)\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "# --- Load benchmark data and create grid  ---------------------\n",
    "\n",
    "# benchmark_data = pd.read_csv('../data/Benchmark/3d_results_Leirvik.csv')\n",
    "# bench_temp   = benchmark_data['temp'].values\n",
    "# bench_precip = benchmark_data['precip_value'].values * 1000\n",
    "# bench_growth = benchmark_data['avg_prediction'].values\n",
    "\n",
    "# bench_Z = griddata(\n",
    "#     points=(bench_temp, bench_precip),\n",
    "#     values=bench_growth,\n",
    "#     xi=(T, P),\n",
    "#     method='linear'\n",
    "# )\n",
    "\n",
    "# # --- Create the benchmark surface --------------------------------------\n",
    "# bench_surface = go.Surface(\n",
    "#     x=T, y=P, z=bench_Z,\n",
    "#     colorscale='Reds',\n",
    "#     showscale=False,\n",
    "#     name='Benchmark'\n",
    "# )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bb8d12",
   "metadata": {},
   "source": [
    "### 2.1.2 Data visualisation\n",
    "In this section we visualise the top-n models in a temperature-precipitation grid \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4c7d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "z=np.mean([surf.z for surf in model_surfaces], axis=0).reshape(T.shape)\n",
    "\n",
    "mean_surface = go.Surface(\n",
    "        x=T, y=P, z=z,\n",
    "        colorscale='Cividis',\n",
    "        opacity=0.85,\n",
    "        showscale=False,\n",
    "        name='mean_surface'\n",
    "    )\n",
    "\n",
    "\n",
    "mean_surface.y=mean_surface.y/1000\n",
    "\n",
    "fig1 = go.Figure(data=mean_surface)\n",
    "fig1.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis_title='Temperature (°C)',\n",
    "        yaxis_title='Precipitation (m)',\n",
    "        zaxis_title='Δ ln(Growth)',\n",
    "        camera=dict(eye=dict(x=2.11, y=0.12, z=0.38)),\n",
    "        zaxis=dict(range=[-0.15, 0.15])\n",
    "    ),\n",
    "    legend=dict(\n",
    "        bgcolor='rgba(255,255,255,0.7)',\n",
    "        bordercolor='black',\n",
    "        borderwidth=1\n",
    "    )\n",
    ")\n",
    "\n",
    "fig1.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a678572c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig.write_image(\"../results/images/Paper/3d_plot_model_vs_Leirvik.pdf\", width=1600, height=1200, scale=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac4685c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- optionally: Save the figure as HTML ---------------------------------------------\n",
    "fig.write_html(f'../results/images/10_best_average_vs_Leirvik.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e854986",
   "metadata": {},
   "source": [
    "## 2.2 Comparing Fixed Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac23f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model of interest\n",
    "node=(32, 16, 16)\n",
    "factory = Model(node, x_train, growth, dropout=0.02, formulation=formulation, penalty=0.0)\n",
    "factory.Depth=len(node)\n",
    "model=factory.get_model()\n",
    "\n",
    "weight_file = f'../results/Model Parameters/{Model_selection}/{date_of_run}/{node}.weights.h5'\n",
    "model.load_params(weight_file)\n",
    "\n",
    "# fit & predict\n",
    "model.fit(lr=lr, min_delta=min_delta, patience=patience, verbose=verbose)\n",
    "\n",
    "model.alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0201c663",
   "metadata": {},
   "outputs": [],
   "source": [
    "#time fixed effects benchmark data\n",
    "bench_time=pd.read_csv('../data/Benchmark/time_fixed_effects_Burke.csv')\n",
    "\n",
    "# cleaning up the benchmark time data\n",
    "bench_time['time'] = bench_time['Unnamed: 0'].astype(str).str.extract(r'(\\d{4})')\n",
    "bench_time['time'] = bench_time['time'].astype(float).astype('Int64')  # nullable integer\n",
    "bench_time.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "\n",
    "#comparing model time fixed effects with benchmark time fixed effects\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(bench_time.iloc[:, 1], bench_time.iloc[:, 0], label='Benchmark', color='red')\n",
    "plt.plot(model.beta, label='Model', color='blue')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e219e69c",
   "metadata": {},
   "source": [
    "## 2.3 Making 2-D plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6ab082",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# --- load benchmark and model predictions as before ---------------------\n",
    "benchmark_data = pd.read_csv('../data/Benchmark/3d_results_Leirvik.csv')\n",
    "bench_temp   = benchmark_data['temp'].values\n",
    "bench_precip = benchmark_data['precip_value'].values * 1000\n",
    "bench_growth = benchmark_data['avg_prediction'].values\n",
    "\n",
    "# --- 1) find the 33rd percentile of precipitation ----------------------\n",
    "percentile=90\n",
    "# flatten the precip grid and compute 33rd percentile\n",
    "p = np.percentile(np.array(P.flatten()), q=percentile)\n",
    "\n",
    "# find the row index in P closest to that precip\n",
    "# (assuming P is shape (n_precip, n_temp) from meshgrid)\n",
    "idx = np.argmin(np.abs(P[:,0] - p))\n",
    "\n",
    "# extract the corresponding temperature axis\n",
    "temp_axis = T[idx, :]\n",
    "\n",
    "\n",
    "# extract model and benchmark slices\n",
    "model_slice = Growth[idx, :]\n",
    "bench_slice = bench_Z[idx, :]\n",
    "\n",
    "# --- 2) make the 2D line plot --------------------------------------------\n",
    "fig2d = go.Figure([\n",
    "    go.Scatter(\n",
    "        x=temp_axis,\n",
    "        y=model_slice,\n",
    "        mode='lines+markers',\n",
    "        name=f'Model @ P≈{p:.1f} mm',\n",
    "    )])\n",
    "# ,\n",
    "#     go.Scatter(\n",
    "#         x=temp_axis,\n",
    "#         y=bench_slice,\n",
    "#         mode='lines+markers',\n",
    "#         name=f'Benchmark @ P≈{p:.1f} mm',\n",
    "#     ),\n",
    "# ])\n",
    "\n",
    "fig2d.update_layout(\n",
    "    title=f'Growth vs Temperature at {percentile}rd-percentile Precipitation ({p:.1f} mm)',\n",
    "    xaxis_title='Temperature (°C)',\n",
    "    yaxis_title='Growth',\n",
    "    xaxis=dict(range=[0, 30]),\n",
    "    legend=dict(\n",
    "        bgcolor='rgba(255,255,255,0.7)',\n",
    "        bordercolor='black',\n",
    "        borderwidth=1\n",
    "    )\n",
    ")\n",
    "\n",
    "fig2d.show()\n",
    "\n",
    "# --- 3) (optional) save as html ------------------------------------------\n",
    "\n",
    "# pio.write_html(fig2d, f'../results/images/2D_slice_Leirvik_comparison_{percentile}.html', auto_open=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341ccd30",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70b3cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#visualise the model: \n",
    "\n",
    "print(model.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763fa21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np=model.beta.to_numpy()\n",
    "\n",
    "last_siz=np[:58]\n",
    "print('Last 6 sizes:', last_siz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91341f49",
   "metadata": {},
   "source": [
    "## 2d surfaces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4284f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px  # for a built‑in qualitative palette\n",
    "\n",
    "# 1) compute the 90th‑percentile precip level\n",
    "percentile = 50\n",
    "p = np.percentile(data['PrecipPopWeight'], percentile)\n",
    "\n",
    "# 2) tolerance window = 0.1 % of p\n",
    "tol = 0.005 * p\n",
    "\n",
    "# 3) slice all obs around that precip band\n",
    "obs_slice = data[np.abs(data['PrecipPopWeight'] - p) <= tol].copy()\n",
    "\n",
    "# 4) (no need for top‑3 any more)\n",
    "\n",
    "# 5) base model trace\n",
    "fig2d = go.Figure([\n",
    "    go.Scatter(\n",
    "        x=temp_axis,\n",
    "        y=model_slice,\n",
    "        mode='lines+markers',\n",
    "        name=f'Model @ P≈{p:.1f} mm',\n",
    "        line=dict(width=2, color='black'),\n",
    "        marker=dict(size=6)\n",
    "    )\n",
    "])\n",
    "\n",
    "# 6) pick a color palette and assign one color per country\n",
    "countries = obs_slice['CountryName'].unique()\n",
    "palette   = px.colors.qualitative.Plotly  # 10 distinct colors\n",
    "color_map = {c: palette[i % len(palette)] for i,c in enumerate(countries)}\n",
    "\n",
    "# 7) plot all observations, colored by country\n",
    "for country in countries:\n",
    "    df_ctry = obs_slice[obs_slice['CountryName'] == country]\n",
    "    fig2d.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df_ctry['TempPopWeight'],\n",
    "            y=df_ctry['GrowthWDI'],\n",
    "            mode='markers',\n",
    "            name=country,\n",
    "            marker=dict(\n",
    "                size=8,\n",
    "                color=color_map[country],\n",
    "                symbol='circle'\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "# 8) finalize layout\n",
    "fig2d.update_layout(\n",
    "    title=f'Growth vs Temperature at {percentile}th‑percentile Precipitation ({p:.1f} mm)',\n",
    "    xaxis_title='Temperature (°C)',\n",
    "    yaxis_title='Growth',\n",
    "    xaxis=dict(range=[0, 30]),\n",
    "    legend=dict(\n",
    "        bgcolor='rgba(255,255,255,0.7)',\n",
    "        bordercolor='black',\n",
    "        borderwidth=1\n",
    "    )\n",
    ")\n",
    "\n",
    "fig2d.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa1189c",
   "metadata": {},
   "source": [
    "## Model confidence plot - based on 10 best cv models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2101fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = dict(np.load(f'../results/metrics/15042025/results.npy', allow_pickle=True).item())\n",
    "\n",
    "# Sort the keys (node configurations) by performance metric and select the top 10.\n",
    "n_models = 10\n",
    "date_of_run = '15042025'\n",
    "ref_model = (8,2,2)  # Reference model configuration\n",
    "top_models = sorted(results, key=lambda node: results[node])[:n_models]\n",
    "\n",
    "\n",
    "# Initialize a list to store the prediction surfaces for each model.\n",
    "prediction_surfaces = []\n",
    "time_fixed_effects=[]\n",
    "country_fixed_effects=[]\n",
    "\n",
    "for node in top_models:\n",
    "    \n",
    "        # Instantiate your model with the given node configuration.\n",
    "    model_instance = Model(nodes=node, x_train=x_train, y_train=growth, dropout=0, formulation=\"global\")\n",
    "    weight_file = f'../results/Model Parameters/CV/{date_of_run}/{str(node)}.weights.h5'\n",
    "    model_instance.load_params(weight_file)  # Load the model weights\n",
    "    model_instance.fit(lr=lr, min_delta=min_delta, patience=patience, verbose=2)\n",
    "    \n",
    "    model_instance.in_sample_predictions\n",
    "    \n",
    "    # Use the model to predict on the standardized (T,P) grid.\n",
    "    growth_pred_flat = model_instance.model_visual.predict(pred_input)\n",
    "    growth_pred_flat = np.reshape(growth_pred_flat, (-1,))   # shape: (900,)\n",
    "    pred = growth_pred_flat.reshape(T.shape)  # reshape to (30, 30)\n",
    "    \n",
    "    prediction_surfaces.append(pred)\n",
    "    time_fixed_effects.append(model_instance.beta)\n",
    "    country_fixed_effects.append(model_instance.alpha)\n",
    "\n",
    "\n",
    "# Convert the list into a NumPy array: shape (10, 30, 30)\n",
    "prediction_surfaces = np.array(prediction_surfaces)\n",
    "\n",
    "# Calculate the pointwise mean and standard deviation across the 10 models.\n",
    "ensemble_mean = np.mean(prediction_surfaces, axis=0)\n",
    "ensemble_std = np.std(prediction_surfaces, axis=0)\n",
    "\n",
    "# Select the Chosen Model (e.g. configuration (8,2,2))\n",
    "chosen_index = top_models.index(ref_model)\n",
    "chosen_surface = prediction_surfaces[chosen_index]\n",
    "\n",
    "model_confidence_plot(ref_model, chosen_surface, ensemble_std=ensemble_std, T=T, P=P, save_as_html=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cf04fd",
   "metadata": {},
   "source": [
    "## plotting the fixed effects from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c4fe8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Squeeze to shape (10, num_countries)\n",
    "country_FE = np.array(country_fixed_effects).squeeze(axis=1)\n",
    "\n",
    "# Number of models\n",
    "n_models = country_FE.shape[0]\n",
    "\n",
    "# Compute mean & sample std across the 10 models (result shape: num_countries)\n",
    "country_FE_mean = np.mean(country_FE, axis=0).squeeze()\n",
    "country_FE_std  = np.std(country_FE,  axis=0, ddof=1).squeeze()\n",
    "\n",
    "# Standard error and 95% CI\n",
    "se    = country_FE_std / np.sqrt(n_models)\n",
    "t_val = stats.t.ppf(0.975, df=n_models - 1)\n",
    "ci    = t_val * se\n",
    "\n",
    "\n",
    "# X-axis indices \n",
    "country_indices = np.arange(country_FE_mean.shape[0])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(x, country_FE_mean, label='Mean')\n",
    "\n",
    "plt.fill_between(\n",
    "    country_indices,\n",
    "    country_FE_mean - ci,\n",
    "    country_FE_mean + ci,\n",
    "    alpha=0.3,\n",
    "    label='95% CI'\n",
    ")\n",
    "plt.title('Mean and 95% Confidence Interval of Country Fixed Effects')\n",
    "plt.xlabel('Country Index')\n",
    "plt.ylabel('Country Fixed Effect')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
