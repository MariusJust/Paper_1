{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Layer, Add\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import he_normal, Zeros\n",
    "from tensorflow.keras.backend import sigmoid\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.python.keras.utils.generic_utils import get_custom_objects\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating Swish activation function\n",
    "def swish(x, beta=1):\n",
    "    \"\"\"\n",
    "    Swish activation function.\n",
    "\n",
    "    ARGUMENTS\n",
    "        * x:    input variable.\n",
    "        * beta: hyperparameter of the Swish activation function.\n",
    "\n",
    "    Returns\n",
    "        * Swish activation function applied to x.\n",
    "    \"\"\"\n",
    "\n",
    "    return x * sigmoid(beta * x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "The swish activation function looks as below: \n",
    "\n",
    "![Sigmoid](../images/swish%20activation.png )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# %% Creating vectorization layer\n",
    "class Vectorize(Layer):\n",
    "    \"\"\"\n",
    "    Layer that vectorizes the second dimension of inputs.\n",
    "    A 1 dimensional tensor is a vector \n",
    "    A 2 dimensional tensor is a matrix\n",
    "    Thus, generally a tensor is a multidimensional array.\n",
    "    \n",
    "    \n",
    "    1. init initialises the class. note that kwargs is a dictionary of keyword arguments.\n",
    "    2. Call is a method that changes the input tensor into a 1D tensor, and removes the NaN values from the tensor.\n",
    "    3.compute_output_shape returns the shape of the output tensor as a tuple.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "  \n",
    "    def __init__(self, **kwargs):\n",
    "        super(Vectorize, self).__init__(**kwargs)\n",
    "        self.dim1 = None\n",
    "\n",
    "    def call(self, x):\n",
    "        \n",
    "        #returns a true-false matrix of the same shape as x, where True is where x is NaN\n",
    "        where_mat = tf.math.is_nan(x)\n",
    "        \n",
    "        #removes the NAN values from x and reshapes it into a 1D tensor. Note that -1 will automatically calculate the size of the tensor, and use it to reshape\n",
    "        y = tf.reshape(x[~where_mat], (1, -1, 1))\n",
    "        #tf.shape(y) returns the shape of y as a tensor, and [1] refers to the second dimension of the tensor\n",
    "        self.dim1 = tf.shape(y)[1]\n",
    "\n",
    "        return y\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        #output shape is a tuple containing a single element, which is the size of the second dimension of the input tensor\n",
    "        return [(1, self.dim1, 1)]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let x be the input matrix:\n",
    "\n",
    "\n",
    "```math\n",
    "x = \\begin{bmatrix}\n",
    "1.0 & \\text{NaN} & 3.0 & \\text{NaN} & 5.0 & 7.0\n",
    "\\end{bmatrix}\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "The output matrix is then:\n",
    "\n",
    "```math\n",
    " y = \\begin{bmatrix}\n",
    "\\begin{bmatrix} \n",
    "1.0 \\\\ \n",
    "3.0 \\\\ \n",
    "5.0 \\\\ \n",
    "7.0 \n",
    "\\end{bmatrix}\n",
    "\\end{bmatrix}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the input tensor is [ 1. nan  3. nan  5.  7.]\n",
      "The output tensor is [[[1.]\n",
      "  [3.]\n",
      "  [5.]\n",
      "  [7.]]]\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the Vectorize class\n",
    "vectorize_layer = Vectorize()\n",
    "\n",
    "# Define an input tensor with some NaN values\n",
    "x = tf.constant([1.0, float('nan'), 3.0, float('nan'), 5.0, 7.0], dtype=tf.float32)\n",
    "print(f'the input tensor is {x}')\n",
    "\n",
    "# Call the vectorize layer on the input tensor\n",
    "result = vectorize_layer(x)\n",
    "\n",
    "\n",
    "# Print the results\n",
    "print(f'The output tensor is {result.numpy()}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Matrixation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# %% Creating matrixation layer\n",
    "class Matrixize(Layer):\n",
    "    \"\"\"\n",
    "    Layer that matrixizes the second dimension of inputs.\n",
    "    \n",
    "    init initialises the class. note that kwargs is a dictionary of keyword arguments.\n",
    "    -N is the number of individuals (or countries in this case) \n",
    "    -T is the number of time steps\n",
    "    -noObs is the number of observations\n",
    "    -mask is a boolean matrix of shape (N, T) where True values indicate missing observations\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, N, T, noObs, mask, **kwargs):\n",
    "        super(Matrixize, self).__init__(**kwargs)\n",
    "        self.N = N\n",
    "        self.T = T\n",
    "        self.noObs = noObs\n",
    "        self.mask = mask\n",
    "\n",
    "    def call(self, x):\n",
    "        #identifies the indices of the False values in the mask. That is the indices of the non-missing observations\n",
    "        where = ~self.mask\n",
    "        \n",
    "        #returns a tensor containing the indices of the non missing observations\n",
    "        indices = tf.cast(tf.where(where), tf.int32)\n",
    "        scatter = tf.scatter_nd(indices, tf.reshape(x, (-1,)), shape=tf.shape(self.mask))\n",
    "        scatter = tf.cast(scatter, dtype=np.float64)\n",
    "\n",
    "        indices = tf.cast(tf.where(~where), tf.int32)\n",
    "        x_nan = tf.ones(self.N * self.T - self.noObs) * np.nan\n",
    "        scatter_nan = tf.scatter_nd(indices, x_nan, shape=tf.shape(self.mask))\n",
    "        scatter_nan = tf.cast(scatter_nan, dtype=np.float64)\n",
    "\n",
    "        return scatter + scatter_nan\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return [(1, self.T, self.N)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example usage of class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input Tensor is the matrix: \n",
    "\n",
    "```math\n",
    "\\text{observations} = \\begin{bmatrix}\n",
    "1.0 & 2.0 & 3.0 & 4.0 & 5.0 & 6.0 & 7.0 & 8.0\n",
    "\\end{bmatrix}\n",
    "```\n",
    "\n",
    "The matrix of missing observations is: \n",
    "```math\n",
    "\\text{mask} = \\begin{bmatrix}\n",
    "\\text{False} & \\text{True}  & \\text{False} & \\text{True}  \\\\\n",
    "\\text{False} & \\text{False} & \\text{True}  & \\text{False} \\\\\n",
    "\\text{True}  & \\text{False} & \\text{False} & \\text{False}\n",
    "\\end{bmatrix}\n",
    "```\n",
    "\n",
    "```math\n",
    "\\text{output} = \\begin{bmatrix}\n",
    "1.0 & \\text{NaN} & 2.0 & \\text{NaN} \\\\\n",
    "3.0 & 4.0 & \\text{NaN} & 5.0 \\\\\n",
    "\\text{NaN} & 6.0 & 7.0 & 8.0\n",
    "\\end{bmatrix}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructed Matrix:\n",
      "[[ 1. nan  2. nan]\n",
      " [ 3.  4. nan  5.]\n",
      " [nan  6.  7.  8.]]\n",
      "Output Shape:\n",
      "[(1, 4, 3)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example Parameters\n",
    "N = 3\n",
    "T = 4\n",
    "noObs = 8\n",
    "mask = np.array([[False, True, False, True],\n",
    "                 [False, False, True, False],\n",
    "                 [True, False, False, False]])\n",
    "\n",
    "# Input observations for the non-missing entries\n",
    "observations = np.array([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0])\n",
    "\n",
    "# Create the Matrixize layer\n",
    "matrixize_layer = Matrixize(N, T, noObs, mask)\n",
    "\n",
    "# Call the layer with the input observations\n",
    "output = matrixize_layer(observations)\n",
    "\n",
    "# Print the resulting matrix\n",
    "print(\"Reconstructed Matrix:\")\n",
    "print(output.numpy())\n",
    "\n",
    "print(\"Output Shape:\")\n",
    "print(matrixize_layer.compute_output_shape(observations.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Extend\n",
    "\n",
    "Very similar to Matricise. Maybe delete ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% Creating extend layer\n",
    "class Extend(Layer):\n",
    "    \"\"\"\n",
    "    Layer that extends the second dimension of inputs.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mask, **kwargs):\n",
    "        super(Extend, self).__init__(**kwargs)\n",
    "        self.mask = mask\n",
    "\n",
    "    def call(self, x):\n",
    "        where = ~self.mask\n",
    "        indices = tf.cast(tf.where(where), tf.int32)\n",
    "        scatter = tf.scatter_nd(indices, tf.reshape(x, (-1,)), shape=tf.shape(self.mask))\n",
    "        scatter = tf.cast(scatter, dtype=np.float64)\n",
    "\n",
    "        indices = tf.cast(tf.where(~where), tf.int32)\n",
    "        mask_tmp = tf.cast(self.mask, tf.int32)\n",
    "        x_nan = tf.ones(tf.reduce_sum(mask_tmp)) * np.nan\n",
    "        scatter_nan = tf.scatter_nd(indices, x_nan, shape=tf.shape(self.mask))\n",
    "        scatter_nan = tf.cast(scatter_nan, dtype=np.float64)\n",
    "\n",
    "        return scatter + scatter_nan\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return [(1, self.T, 1)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% Creating dummy layer\n",
    "class Dummies(Layer):\n",
    "    \"\"\"\n",
    "    Layer that creates country and time dummies.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, N, T, time_periods_na, **kwargs):\n",
    "        super(Dummies, self).__init__(**kwargs)\n",
    "        self.N = N\n",
    "        self.T = T\n",
    "        self.time_periods_na = time_periods_na\n",
    "        self.noObs = None\n",
    "\n",
    "    def call(self, x):\n",
    "        where_mat = tf.transpose(tf.math.is_nan(x))\n",
    "\n",
    "        for t in range(self.T):\n",
    "            idx = tf.where(~where_mat[:, t, 0])\n",
    "            idx = tf.reshape(idx, (-1,))\n",
    "\n",
    "            D_t = tf.eye(self.N)\n",
    "            D_t = tf.gather(D_t, idx, axis=0)\n",
    "\n",
    "            if t == 0:\n",
    "                Delta_1 = D_t\n",
    "\n",
    "                Delta_2 = tf.matmul(D_t, tf.ones((self.N, 1)))\n",
    "\n",
    "            else:\n",
    "                Delta_1 = tf.concat([Delta_1, D_t], axis=0)\n",
    "\n",
    "                Delta_2 = tf.concat([Delta_2, tf.zeros((tf.shape(Delta_2)[0], 1))], axis=1)\n",
    "\n",
    "                Delta_2_tmp = tf.matmul(D_t, tf.ones((self.N, 1)))\n",
    "                Delta_2_tmp = tf.concat([tf.zeros((tf.shape(Delta_2_tmp)[0], t)), Delta_2_tmp], axis=1)\n",
    "\n",
    "                Delta_2 = tf.concat([Delta_2, Delta_2_tmp], axis=0)\n",
    "\n",
    "        Delta_1 = Delta_1[:, 1:]\n",
    "        Delta_2 = Delta_2[:, self.time_periods_na + 1:]\n",
    "\n",
    "        self.noObs = tf.shape(Delta_1)[0]\n",
    "\n",
    "        Delta_1 = tf.reshape(Delta_1, (1, self.noObs, self.N - 1))\n",
    "        Delta_2 = tf.reshape(Delta_2, (1, self.noObs, self.T - (self.time_periods_na + 1)))\n",
    "\n",
    "        return [Delta_1, Delta_2]\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return [(1, self.noObs, self.N - 1), (1, self.noObs, self.T - (self.time_periods_na + 1))]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example usage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input matrix x with NaN values\n",
    "N = 4  # Number of countries\n",
    "T = 3  # Number of time periods\n",
    "time_periods_na = 1  # Number of missing time periods\n",
    "\n",
    "x = tf.constant([\n",
    "    [1.0, np.nan, 3.0],\n",
    "    [2.0, 4.0, 5.0],\n",
    "    [np.nan, 6.0, 7.0],\n",
    "    [8.0, 9.0, np.nan]\n",
    "], dtype=tf.float32)\n",
    "\n",
    "# Initialize and apply the Dummies layer\n",
    "dummies_layer = Dummies(N=N, T=T, time_periods_na=time_periods_na)\n",
    "Delta_1, Delta_2 = dummies_layer(x)\n",
    "\n",
    "# Print the results\n",
    "print(\"Delta_1 (Country Dummies):\")\n",
    "print(Delta_1.numpy())\n",
    "\n",
    "print(\"\\nDelta_2 (Time Dummies):\")\n",
    "print(Delta_2.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def individual_loss(mask):\n",
    "    \"\"\"\n",
    "    Loss function (in two layers so that it can be interpreted by tensorflow).\n",
    "\n",
    "    ARGUMENTS\n",
    "        * mask: mask used to identify missing observations.\n",
    "\n",
    "    Returns\n",
    "        * loss: loss function evaluated in y_true and y_pred.\n",
    "    \"\"\"\n",
    "\n",
    "    def loss(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        ARGUMENTS\n",
    "            * y_true: observed targets.\n",
    "            * y_pred: predicted targets.\n",
    "\n",
    "        RETURNS\n",
    "            * loss function evaluated in y_true and y_pred.\n",
    "        \"\"\"\n",
    "\n",
    "        y_true_transf = tf.reshape(y_true[~mask], (1, -1, 1))\n",
    "        y_pred_transf = tf.reshape(y_pred[~mask], (1, -1, 1))\n",
    "\n",
    "        return tf.reduce_mean(tf.math.squared_difference(y_true_transf, y_pred_transf), axis=1)\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
