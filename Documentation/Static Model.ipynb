{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class static_model:\n",
    "    \"\"\"\n",
    "    Class implementing the static neural network model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, nodes, x_train, y_train, pop_train, formulation='global'):\n",
    "        \"\"\"\n",
    "        Instantiating class.\n",
    "\n",
    "        ARGUMENT\n",
    "            * nodes:          tuple defining the model architecture.\n",
    "            * x_train:        dict of TxN_r dataframes of input data (aligned) with a key for each region.\n",
    "            * y_train:        dict of TxN_r dataframes of target data (aligned) with a key for each region.\n",
    "            * pop_train:      dict of TxN_r dataframes of population data (aligned) with a key for each region.\n",
    "            * formulation:    str determining the formulation of the model. Must be one of 'global' or 'regional' or 'national'.\n",
    "\n",
    "        NB: regions are inferred from the keys of x_train and y_train.\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialization\n",
    "        self.nodes = nodes\n",
    "        self.Depth = len(self.nodes)\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.pop_train = pop_train\n",
    "        self.formulation = formulation\n",
    "\n",
    "        self.individuals = {}\n",
    "        self.N = {}\n",
    "        self.noObs = {}\n",
    "\n",
    "        self.time_periods_na = {}\n",
    "        self.time_periods_not_na = {}\n",
    "\n",
    "        self.in_sample_pred = {}\n",
    "        self.R2 = {}\n",
    "        self.MSE = {}\n",
    "\n",
    "        self.Min = {}\n",
    "        self.Max = {}\n",
    "        self.quant025 = {}\n",
    "        self.quant05 = {}\n",
    "        self.quant95 = {}\n",
    "        self.quant975 = {}\n",
    "\n",
    "        self.x_train_np = {}\n",
    "        self.y_train_df = {}\n",
    "\n",
    "        self.x_train_transf = {}\n",
    "        self.y_train_transf = {}\n",
    "        self.pop_train_transf = {}\n",
    "\n",
    "        self.mask = {}\n",
    "\n",
    "        self.losses = None\n",
    "        self.epochs = None\n",
    "        self.params = None\n",
    "        self.BIC = None\n",
    "\n",
    "        self.model_pred = None\n",
    "\n",
    "        # Preparing data\n",
    "        self.regions = list(self.x_train.keys())\n",
    "        self.no_regions = len(self.regions)\n",
    "\n",
    "        self.T = self.x_train[self.regions[0]].shape[0]\n",
    "        self.time_periods = self.x_train[self.regions[0]].index.values\n",
    "\n",
    "        for region in self.regions:\n",
    "            self.individuals[region] = x_train[region].columns\n",
    "            self.time_periods_not_na[region] = np.sum(~np.isnan(self.x_train[region]), axis=1) > 0\n",
    "            self.time_periods_na[region] = np.sum(~self.time_periods_not_na[region])\n",
    "\n",
    "            self.N[region] = len(self.individuals[region])\n",
    "\n",
    "            self.x_train_np[region] = np.array(np.log(self.x_train[region] / self.pop_train[region]))\n",
    "            self.y_train_df[region] = np.log(self.y_train[region] / self.pop_train[region])\n",
    "\n",
    "            self.noObs[region] = self.N[region] * self.T - np.isnan(self.x_train_np[region]).sum()\n",
    "\n",
    "            self.Min[region] = np.nanmin(self.x_train_np[region])\n",
    "            self.Max[region] = np.nanmax(self.x_train_np[region])\n",
    "            self.quant025[region] = np.nanquantile(self.x_train_np[region], 0.025)\n",
    "            self.quant05[region] = np.nanquantile(self.x_train_np[region], 0.05)\n",
    "            self.quant95[region] = np.nanquantile(self.x_train_np[region], 0.95)\n",
    "            self.quant975[region] = np.nanquantile(self.x_train_np[region], 0.975)\n",
    "\n",
    "            for individual in self.individuals[region]:\n",
    "                pos = np.where(self.individuals[region] == individual)[0][0]\n",
    "\n",
    "                self.Min[individual] = np.nanmin(self.x_train_np[region][:, pos])\n",
    "                self.Max[individual] = np.nanmax(self.x_train_np[region][:, pos])\n",
    "                self.quant025[individual] = np.nanquantile(self.x_train_np[region][:, pos], 0.025)\n",
    "                self.quant05[individual] = np.nanquantile(self.x_train_np[region][:, pos], 0.05)\n",
    "                self.quant95[individual] = np.nanquantile(self.x_train_np[region][:, pos], 0.95)\n",
    "                self.quant975[individual] = np.nanquantile(self.x_train_np[region][:, pos], 0.975)\n",
    "\n",
    "            self.x_train_transf[region] = self.x_train[region].copy()\n",
    "            self.y_train_transf[region] = self.y_train[region].copy()\n",
    "            self.pop_train_transf[region] = self.pop_train[region].copy()\n",
    "\n",
    "            self.x_train_transf[region] = np.array(np.log(self.x_train_transf[region] / self.pop_train_transf[region]))\n",
    "            self.y_train_transf[region] = np.array(np.log(self.y_train_transf[region] / self.pop_train_transf[region]))\n",
    "\n",
    "            self.mask[region] = np.isnan(self.x_train_transf[region])\n",
    "\n",
    "            if region == self.regions[0]:\n",
    "                self.individuals['global'] = list(self.individuals[region])\n",
    "                self.time_periods_not_na['global'] = np.sum(~np.isnan(self.x_train[region]), axis=1) > 0\n",
    "\n",
    "                self.x_train_transf['global'] = self.x_train[self.regions[0]].copy()\n",
    "                self.y_train_transf['global'] = self.y_train[self.regions[0]].copy()\n",
    "                self.pop_train_transf['global'] = self.pop_train[self.regions[0]].copy()\n",
    "\n",
    "            else:\n",
    "                self.individuals['global'] = self.individuals['global'] + list(self.individuals[region])\n",
    "                self.time_periods_not_na['global'] = self.time_periods_not_na['global'] | (np.sum(~np.isnan(self.x_train[region]), axis=1) > 0)\n",
    "\n",
    "                self.x_train_transf['global'] = pd.concat([self.x_train_transf['global'], self.x_train[region]], axis=1)\n",
    "                self.y_train_transf['global'] = pd.concat([self.y_train_transf['global'], self.y_train[region]], axis=1)\n",
    "                self.pop_train_transf['global'] = pd.concat([self.pop_train_transf['global'], self.pop_train[region]], axis=1)\n",
    "\n",
    "        self.time_periods_na['global'] = np.sum(~self.time_periods_not_na['global'])\n",
    "\n",
    "        self.N['global'] = np.sum(list(self.N.values()))\n",
    "\n",
    "        self.x_train_np['global'] = np.array(np.log(self.x_train_transf['global'] / self.pop_train_transf['global']))\n",
    "        self.noObs['global'] = self.N['global'] * self.T - np.isnan(self.x_train_np['global']).sum()\n",
    "\n",
    "        self.Min['global'] = np.nanmin(self.x_train_np['global'])\n",
    "        self.Max['global'] = np.nanmax(self.x_train_np['global'])\n",
    "        self.quant025['global'] = np.nanquantile(self.x_train_np['global'], 0.025)\n",
    "        self.quant05['global'] = np.nanquantile(self.x_train_np['global'], 0.05)\n",
    "        self.quant95['global'] = np.nanquantile(self.x_train_np['global'], 0.95)\n",
    "        self.quant975['global'] = np.nanquantile(self.x_train_np['global'], 0.975)\n",
    "\n",
    "        self.x_train_transf['global'] = np.array(np.log(self.x_train_transf['global'] / self.pop_train_transf['global']))\n",
    "        self.y_train_transf['global'] = np.array(np.log(self.y_train_transf['global'] / self.pop_train_transf['global']))\n",
    "\n",
    "        self.mask['global'] = np.isnan(self.x_train_transf['global'])\n",
    "\n",
    "        # Setting up the model\n",
    "        if formulation == 'national':\n",
    "            # %% Initialization\n",
    "            input_x_country = [None] * self.N['global']\n",
    "            input_first = [None] * self.N['global']\n",
    "            input_last = [None] * self.N['global']\n",
    "\n",
    "            output_tmp = [None] * self.N['global']\n",
    "            output_ext = [None] * self.N['global']\n",
    "\n",
    "            self.inputs = [None] * self.N['global']\n",
    "            self.targets = [None] * self.N['global']\n",
    "\n",
    "            self.Mask_country = [None] * self.N['global']\n",
    "            self.loss_list = [None] * self.N['global']\n",
    "\n",
    "            self.output_layer = [None] * self.N['global']\n",
    "            kernel_initializer_4 = [None] * self.N['global']\n",
    "\n",
    "            # Building architecture for the mean\n",
    "            hidden_1 = [None] * self.N['global']\n",
    "\n",
    "            kernel_initializer_1 = he_normal()\n",
    "            bias_initializer_1 = Zeros()\n",
    "\n",
    "            self.hidden_1_layer = Dense(self.nodes[0], activation='swish', use_bias=True,\n",
    "                                        kernel_initializer=kernel_initializer_1, bias_initializer=bias_initializer_1)\n",
    "\n",
    "            if self.Depth > 1:\n",
    "                hidden_2 = [None] * self.N['global']\n",
    "\n",
    "                kernel_initializer_2 = he_normal()\n",
    "                bias_initializer_2 = Zeros()\n",
    "\n",
    "                self.hidden_2_layer = Dense(self.nodes[1], activation='swish', use_bias=True,\n",
    "                                            kernel_initializer=kernel_initializer_2,\n",
    "                                            bias_initializer=bias_initializer_2)\n",
    "\n",
    "                if self.Depth > 2:\n",
    "                    hidden_3 = [None] * self.N['global']\n",
    "\n",
    "                    kernel_initializer_3 = he_normal()\n",
    "                    bias_initializer_3 = Zeros()\n",
    "\n",
    "                    self.hidden_3_layer = Dense(self.nodes[2], activation='swish', use_bias=True,\n",
    "                                                kernel_initializer=kernel_initializer_3,\n",
    "                                                bias_initializer=bias_initializer_3)\n",
    "\n",
    "            country_counter = 0\n",
    "\n",
    "            # Creating the forward pass\n",
    "            for i in range(self.no_regions):\n",
    "                for j in range(self.N[self.regions[i]]):\n",
    "                    input_x_country[country_counter] = Input(shape=(1, self.T, 1))\n",
    "\n",
    "                    self.inputs[country_counter] = tf.reshape(tf.convert_to_tensor(self.x_train_transf[self.regions[i]][:, j]), (1, self.T, 1))\n",
    "                    self.targets[country_counter] = tf.reshape(tf.convert_to_tensor(self.y_train_transf[self.regions[i]][:, j]), (1, self.T, 1))\n",
    "\n",
    "                    self.Mask_country[country_counter] = tf.reshape(tf.convert_to_tensor(self.mask[self.regions[i]][:, j]), (1, self.T, 1))\n",
    "                    self.loss_list[country_counter] = individual_loss(mask=self.Mask_country[country_counter])\n",
    "\n",
    "                    # For the mean\n",
    "                    input_first[country_counter] = Vectorize()(input_x_country[country_counter])\n",
    "                    hidden_1[country_counter] = self.hidden_1_layer(input_first[country_counter])\n",
    "\n",
    "                    if self.Depth > 1:\n",
    "                        hidden_2[country_counter] = self.hidden_2_layer(hidden_1[country_counter])\n",
    "\n",
    "                        if self.Depth > 2:\n",
    "                            hidden_3[country_counter] = self.hidden_3_layer(hidden_2[country_counter])\n",
    "\n",
    "                            input_last[country_counter] = hidden_3[country_counter]\n",
    "\n",
    "                        else:\n",
    "                            input_last[country_counter] = hidden_2[country_counter]\n",
    "\n",
    "                    else:\n",
    "                        input_last[country_counter] = hidden_1[country_counter]\n",
    "\n",
    "                    kernel_initializer_4[country_counter] = he_normal()\n",
    "\n",
    "                    self.output_layer[country_counter] = Dense(1, activation='linear', use_bias=False,\n",
    "                                                               kernel_initializer=kernel_initializer_4[country_counter])\n",
    "\n",
    "                    output_tmp[country_counter] = self.output_layer[country_counter](input_last[country_counter])\n",
    "\n",
    "                    output_ext[country_counter] = Extend(mask=self.Mask_country[country_counter])(output_tmp[country_counter])\n",
    "\n",
    "                    country_counter = country_counter + 1\n",
    "\n",
    "            # Compiling the model\n",
    "            self.model = Model(inputs=input_x_country, outputs=output_ext)\n",
    "\n",
    "            # Counting number of parameters\n",
    "            self.m = self.hidden_1_layer.count_params()\n",
    "\n",
    "            if self.Depth > 1:\n",
    "                self.m = self.m + self.hidden_2_layer.count_params()\n",
    "\n",
    "                if self.Depth > 2:\n",
    "                    self.m = self.m + self.hidden_3_layer.count_params()\n",
    "\n",
    "            self.m_alt = self.m\n",
    "\n",
    "            for i in range(self.N['global']):\n",
    "                self.m = self.m + self.output_layer[i].count_params()\n",
    "\n",
    "            # Setting up prediction model\n",
    "            self.input_x_pred = [None] * self.N['global']\n",
    "            self.hidden_1_pred = [None] * self.N['global']\n",
    "            self.hidden_2_pred = [None] * self.N['global']\n",
    "            self.hidden_3_pred = [None] * self.N['global']\n",
    "            self.output_pred = [None] * self.N['global']\n",
    "            self.input_last_pred = [None] * self.N['global']\n",
    "\n",
    "            self.model_pred = {}\n",
    "\n",
    "            for i in range(self.N['global']):\n",
    "                self.input_x_pred[i] = Input(shape=(1, None, 1))\n",
    "                self.hidden_1_pred[i] = self.hidden_1_layer(self.input_x_pred[i])\n",
    "\n",
    "                if self.Depth > 1:\n",
    "                    self.hidden_2_pred[i] = self.hidden_2_layer(self.hidden_1_pred[i])\n",
    "\n",
    "                    if self.Depth > 2:\n",
    "                        self.hidden_3_pred[i] = self.hidden_3_layer(self.hidden_2_pred[i])\n",
    "                        self.input_last_pred[i] = self.hidden_3_pred[i]\n",
    "\n",
    "                    else:\n",
    "                        self.input_last_pred[i] = self.hidden_2_pred[i]\n",
    "\n",
    "                else:\n",
    "                    self.input_last_pred[i] = self.hidden_1_pred[i]\n",
    "\n",
    "                self.output_pred[i] = self.output_layer[i](self.input_last_pred[i])\n",
    "\n",
    "                self.model_pred[self.individuals['global'][i]] = Model(inputs=self.input_x_pred[i], outputs=self.output_pred[i])\n",
    "\n",
    "        elif formulation == 'regional':\n",
    "            # %% Initialization\n",
    "            input_x = [None] * self.no_regions\n",
    "            input_first = [None] * self.no_regions\n",
    "            input_last = [None] * self.no_regions\n",
    "\n",
    "            output_tmp = [None] * self.no_regions\n",
    "            output = [None] * self.no_regions\n",
    "            output_matrix = [None] * self.no_regions\n",
    "\n",
    "            Delta_1 = [None] * self.no_regions\n",
    "            Delta_2 = [None] * self.no_regions\n",
    "            country_FE = [None] * self.no_regions\n",
    "            time_FE = [None] * self.no_regions\n",
    "\n",
    "            self.country_FE_layer = [None] * self.no_regions\n",
    "            self.time_FE_layer = [None] * self.no_regions\n",
    "\n",
    "            self.inputs = [None] * self.no_regions\n",
    "            self.targets = [None] * self.no_regions\n",
    "\n",
    "            self.Mask = [None] * self.no_regions\n",
    "            self.loss_list = [None] * self.no_regions\n",
    "\n",
    "            self.output_layer = [None] * self.no_regions\n",
    "            kernel_initializer_4 = [None] * self.no_regions\n",
    "\n",
    "            # Building architecture for the mean\n",
    "            hidden_1 = [None] * self.no_regions\n",
    "\n",
    "            kernel_initializer_1 = he_normal()\n",
    "            bias_initializer_1 = Zeros()\n",
    "\n",
    "            self.hidden_1_layer = Dense(self.nodes[0], activation='swish', use_bias=True,\n",
    "                                   kernel_initializer=kernel_initializer_1, bias_initializer=bias_initializer_1)\n",
    "\n",
    "            if self.Depth > 1:\n",
    "                hidden_2 = [None] * self.no_regions\n",
    "\n",
    "                kernel_initializer_2 = he_normal()\n",
    "                bias_initializer_2 = Zeros()\n",
    "\n",
    "                self.hidden_2_layer = Dense(self.nodes[1], activation='swish', use_bias=True,\n",
    "                                       kernel_initializer=kernel_initializer_2, bias_initializer=bias_initializer_2)\n",
    "\n",
    "                if self.Depth > 2:\n",
    "                    hidden_3 = [None] * self.no_regions\n",
    "\n",
    "                    kernel_initializer_3 = he_normal()\n",
    "                    bias_initializer_3 = Zeros()\n",
    "\n",
    "                    self.hidden_3_layer = Dense(self.nodes[2], activation='swish', use_bias=True,\n",
    "                                           kernel_initializer=kernel_initializer_3, bias_initializer=bias_initializer_3)\n",
    "\n",
    "            # Creating the forward pass\n",
    "            for i in range(self.no_regions):\n",
    "                input_x[i] = Input(shape=(1, self.T, self.N[self.regions[i]]))\n",
    "\n",
    "                self.inputs[i] = tf.reshape(tf.convert_to_tensor(self.x_train_transf[self.regions[i]]), (1, self.T, self.N[self.regions[i]]))\n",
    "                self.targets[i] = tf.reshape(tf.convert_to_tensor(self.y_train_transf[self.regions[i]]), (1, self.T, self.N[self.regions[i]]))\n",
    "\n",
    "                self.Mask[i] = tf.reshape(tf.convert_to_tensor(self.mask[self.regions[i]]), (1, self.T, self.N[self.regions[i]]))\n",
    "                self.loss_list[i] = individual_loss(mask=self.Mask[i])\n",
    "\n",
    "                # For the mean\n",
    "                Delta_1[i], Delta_2[i] = Dummies(N=self.N[self.regions[i]], T=self.T,\n",
    "                                                 time_periods_na=self.time_periods_na[self.regions[i]])(input_x[i])\n",
    "\n",
    "                input_first[i] = Vectorize()(input_x[i])\n",
    "\n",
    "                hidden_1[i] = self.hidden_1_layer(input_first[i])\n",
    "\n",
    "                if self.Depth > 1:\n",
    "                    hidden_2[i] = self.hidden_2_layer(hidden_1[i])\n",
    "\n",
    "                    if self.Depth > 2:\n",
    "                        hidden_3[i] = self.hidden_3_layer(hidden_2[i])\n",
    "\n",
    "                        input_last[i] = hidden_3[i]\n",
    "\n",
    "                    else:\n",
    "                        input_last[i] = hidden_2[i]\n",
    "\n",
    "                else:\n",
    "                    input_last[i] = hidden_1[i]\n",
    "\n",
    "                kernel_initializer_4[i] = he_normal()\n",
    "\n",
    "                self.output_layer[i] = Dense(1, activation='linear', use_bias=False,\n",
    "                                        kernel_initializer=kernel_initializer_4[i])\n",
    "\n",
    "                output_tmp[i] = self.output_layer[i](input_last[i])\n",
    "\n",
    "                # Adding fixed effects\n",
    "                kernel_initializer_5 = Zeros()\n",
    "                self.time_FE_layer[i] = Dense(1, activation='linear', use_bias=False,\n",
    "                                              kernel_initializer=kernel_initializer_5)\n",
    "\n",
    "                time_FE[i] = self.time_FE_layer[i](Delta_2[i])\n",
    "\n",
    "                kernel_initializer_6 = Zeros()\n",
    "                self.country_FE_layer[i] = Dense(1, activation='linear', use_bias=False,\n",
    "                                                 kernel_initializer=kernel_initializer_6)\n",
    "\n",
    "                country_FE[i] = self.country_FE_layer[i](Delta_1[i])\n",
    "\n",
    "                output[i] = Add()([time_FE[i], country_FE[i], output_tmp[i]])\n",
    "\n",
    "                output_matrix[i] = Matrixize(N=self.N[self.regions[i]], T=self.T, noObs=self.noObs[self.regions[i]],\n",
    "                                             mask=self.Mask[i])(output[i])\n",
    "\n",
    "            # Compiling the model\n",
    "            self.model = Model(inputs=input_x, outputs=output_matrix)\n",
    "\n",
    "            # Counting number of parameters\n",
    "            self.m = self.hidden_1_layer.count_params()\n",
    "\n",
    "            if self.Depth > 1:\n",
    "                self.m = self.m + self.hidden_2_layer.count_params()\n",
    "\n",
    "                if self.Depth > 2:\n",
    "                    self.m = self.m + self.hidden_3_layer.count_params()\n",
    "\n",
    "            self.m_alt = self.m\n",
    "\n",
    "            for i in range(self.no_regions):\n",
    "                self.m = self.m + self.output_layer[i].count_params()\n",
    "\n",
    "            # Setting up prediction model\n",
    "            self.input_x_pred = [None] * self.no_regions\n",
    "            self.hidden_1_pred = [None] * self.no_regions\n",
    "            self.hidden_2_pred = [None] * self.no_regions\n",
    "            self.hidden_3_pred = [None] * self.no_regions\n",
    "            self.output_pred = [None] * self.no_regions\n",
    "            self.input_last_pred = [None] * self.no_regions\n",
    "\n",
    "            self.model_pred = {}\n",
    "\n",
    "            for i in range(self.no_regions):\n",
    "                self.input_x_pred[i] = Input(shape=(1, None, 1))\n",
    "                self.hidden_1_pred[i] = self.hidden_1_layer(self.input_x_pred[i])\n",
    "\n",
    "                if self.Depth > 1:\n",
    "                    self.hidden_2_pred[i] = self.hidden_2_layer(self.hidden_1_pred[i])\n",
    "\n",
    "                    if self.Depth > 2:\n",
    "                        self.hidden_3_pred[i] = self.hidden_3_layer(self.hidden_2_pred[i])\n",
    "                        self.input_last_pred[i] = self.hidden_3_pred[i]\n",
    "\n",
    "                    else:\n",
    "                        self.input_last_pred[i] = self.hidden_2_pred[i]\n",
    "\n",
    "                else:\n",
    "                    self.input_last_pred[i] = self.hidden_1_pred[i]\n",
    "\n",
    "                self.output_pred[i] = self.output_layer[i](self.input_last_pred[i])\n",
    "\n",
    "                self.model_pred[self.regions[i]] = Model(inputs=self.input_x_pred[i], outputs=self.output_pred[i])\n",
    "\n",
    "            # Initialization for fixed effects\n",
    "            self.alpha = {}\n",
    "            self.beta = {}\n",
    "\n",
    "        else:\n",
    "            # %% Initialization\n",
    "            input_x = Input(shape=(1, self.T, self.N['global']))\n",
    "\n",
    "            self.inputs = tf.reshape(tf.convert_to_tensor(self.x_train_transf['global']), (1, self.T, self.N['global']))\n",
    "            self.targets = tf.reshape(tf.convert_to_tensor(self.y_train_transf['global']), (1, self.T, self.N['global']))\n",
    "\n",
    "            self.Mask = tf.reshape(tf.convert_to_tensor(self.mask['global']), (1, self.T, self.N['global']))\n",
    "\n",
    "            # Creating the forward pass\n",
    "            kernel_initializer_1 = he_normal()\n",
    "            bias_initializer_1 = Zeros()\n",
    "\n",
    "            kernel_initializer_5 = Zeros()\n",
    "            kernel_initializer_6 = Zeros()\n",
    "\n",
    "            self.time_FE_layer = Dense(1, activation='linear', use_bias=False, kernel_initializer=kernel_initializer_5)\n",
    "            self.country_FE_layer = Dense(1, activation='linear', use_bias=False, kernel_initializer=kernel_initializer_6)\n",
    "\n",
    "            Delta_1, Delta_2 = Dummies(N=self.N['global'], T=self.T, time_periods_na=self.time_periods_na['global'])(input_x)\n",
    "\n",
    "            time_FE = self.time_FE_layer(Delta_2)\n",
    "            country_FE = self.country_FE_layer(Delta_1)\n",
    "\n",
    "            input_first = Vectorize()(input_x)\n",
    "\n",
    "            self.hidden_1_layer = Dense(self.nodes[0], activation='swish', use_bias=True,\n",
    "                                   kernel_initializer=kernel_initializer_1, bias_initializer=bias_initializer_1)\n",
    "\n",
    "            hidden_1 = self.hidden_1_layer(input_first)\n",
    "\n",
    "            if self.Depth > 1:\n",
    "                kernel_initializer_2 = he_normal()\n",
    "                bias_initializer_2 = Zeros()\n",
    "\n",
    "                self.hidden_2_layer = Dense(self.nodes[1], activation='swish', use_bias=True,\n",
    "                                       kernel_initializer=kernel_initializer_2, bias_initializer=bias_initializer_2)\n",
    "\n",
    "                hidden_2 = self.hidden_2_layer(hidden_1)\n",
    "\n",
    "                if self.Depth > 2:\n",
    "                    kernel_initializer_3 = he_normal()\n",
    "                    bias_initializer_3 = Zeros()\n",
    "\n",
    "                    self.hidden_3_layer = Dense(self.nodes[2], activation='swish', use_bias=True,\n",
    "                                           kernel_initializer=kernel_initializer_3, bias_initializer=bias_initializer_3)\n",
    "\n",
    "                    hidden_3 = self.hidden_3_layer(hidden_2)\n",
    "\n",
    "                    input_last = hidden_3\n",
    "\n",
    "                else:\n",
    "                    input_last = hidden_2\n",
    "\n",
    "            else:\n",
    "                input_last = hidden_1\n",
    "\n",
    "            kernel_initializer_4 = he_normal()\n",
    "\n",
    "            self.output_layer = Dense(1, activation='linear', use_bias=False, kernel_initializer=kernel_initializer_4)\n",
    "\n",
    "            output_tmp = self.output_layer(input_last)\n",
    "\n",
    "            # Adding fixed effects\n",
    "            output = Add()([time_FE, country_FE, output_tmp])\n",
    "\n",
    "            output_matrix = Matrixize(N=self.N['global'], T=self.T, noObs=self.noObs['global'], mask=self.Mask)(output)\n",
    "\n",
    "            # Compiling the model\n",
    "            self.model = Model(inputs=input_x, outputs=output_matrix)\n",
    "\n",
    "            # Counting number of parameters\n",
    "            self.m = self.hidden_1_layer.count_params()\n",
    "\n",
    "            if self.Depth > 1:\n",
    "                self.m = self.m + self.hidden_2_layer.count_params()\n",
    "\n",
    "                if self.Depth > 2:\n",
    "                    self.m = self.m + self.hidden_3_layer.count_params()\n",
    "\n",
    "            self.m_alt = self.m\n",
    "\n",
    "            self.m = self.m + self.output_layer.count_params()\n",
    "\n",
    "            # Setting up prediction model\n",
    "            input_x_pred = Input(shape=(1, None, 1))\n",
    "            hidden_1_pred = self.hidden_1_layer(input_x_pred)\n",
    "\n",
    "            if self.Depth > 1:\n",
    "                hidden_2_pred = self.hidden_2_layer(hidden_1_pred)\n",
    "\n",
    "                if self.Depth > 2:\n",
    "                    hidden_3_pred = self.hidden_3_layer(hidden_2_pred)\n",
    "                    input_last_pred = hidden_3_pred\n",
    "\n",
    "                else:\n",
    "                    input_last_pred = hidden_2_pred\n",
    "\n",
    "            else:\n",
    "                input_last_pred = hidden_1_pred\n",
    "\n",
    "            output_pred = self.output_layer(input_last_pred)\n",
    "\n",
    "            self.model_pred = Model(inputs=input_x_pred, outputs=output_pred)\n",
    "\n",
    "    def fit(self, lr=0.001, min_delta=1e-6, patience=100, verbose=1):\n",
    "        \"\"\"\n",
    "        Fitting the model.\n",
    "\n",
    "        ARGUMENTS\n",
    "            * lr:            initial learning rate of the Adam optimizer.\n",
    "            * min_delta:     tolerance to be used for optimization.\n",
    "            * patience:      patience to be used for optimization.\n",
    "            * verbose:       verbosity mode for optimization.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.formulation == 'national':\n",
    "            self.model.compile(optimizer=Adam(lr), loss=self.loss_list, loss_weights=[1 / self.N['global']] * self.N['global'])\n",
    "\n",
    "        elif self.formulation == 'regional':\n",
    "            self.model.compile(optimizer=Adam(lr), loss=self.loss_list, loss_weights=[1 / self.no_regions] * self.no_regions)\n",
    "\n",
    "        else:\n",
    "            self.model.compile(optimizer=Adam(lr), loss=individual_loss(mask=self.Mask))\n",
    "\n",
    "        callbacks = [EarlyStopping(monitor='loss', mode='min', min_delta=min_delta, patience=patience,\n",
    "                                   restore_best_weights=True, verbose=verbose)]\n",
    "\n",
    "        self.model.fit(self.inputs, self.targets, callbacks=callbacks, batch_size=1, epochs=int(1e6), verbose=verbose, shuffle=False)\n",
    "\n",
    "        self.losses = self.model.history.history\n",
    "        self.epochs = self.model.history.epoch\n",
    "\n",
    "        self.params = self.model.get_weights()\n",
    "\n",
    "        # Saving fixed effects estimates\n",
    "        if self.formulation == 'national':\n",
    "            pass\n",
    "\n",
    "        elif self.formulation == 'regional':\n",
    "            for i in range(self.no_regions):\n",
    "                self.alpha[self.regions[i]] = pd.DataFrame(self.country_FE_layer[i].weights[0].numpy().T)\n",
    "                self.alpha[self.regions[i]].columns = self.individuals[self.regions[i]][1:]\n",
    "\n",
    "                self.beta[self.regions[i]] = pd.DataFrame(self.time_FE_layer[i].weights[0].numpy())\n",
    "                self.beta[self.regions[i]].set_index(self.time_periods[self.time_periods_na[self.regions[i]] + 1:], inplace=True)\n",
    "\n",
    "        else:\n",
    "            self.alpha = pd.DataFrame(self.country_FE_layer.weights[0].numpy().T)\n",
    "            self.alpha.columns = self.individuals['global'][1:]\n",
    "\n",
    "            self.beta = pd.DataFrame(self.time_FE_layer.weights[0].numpy())\n",
    "            self.beta.set_index(self.time_periods[self.time_periods_not_na['global']][1:], inplace=True)\n",
    "\n",
    "    def load_params(self, filepath):\n",
    "        \"\"\"\n",
    "        Loading model parameters.\n",
    "\n",
    "         ARGUMENTS\n",
    "            * filepath: string containing path/name of saved file.\n",
    "        \"\"\"\n",
    "\n",
    "        self.model.load_weights(filepath)\n",
    "        self.params = self.model.get_weights()\n",
    "\n",
    "        # Saving fixed effects estimates\n",
    "        if self.formulation == 'national':\n",
    "            pass\n",
    "\n",
    "        elif self.formulation == 'regional':\n",
    "            for i in range(self.no_regions):\n",
    "                self.alpha[self.regions[i]] = pd.DataFrame(self.country_FE_layer[i].weights[0].numpy().T)\n",
    "                self.alpha[self.regions[i]].columns = self.individuals[self.regions[i]][1:]\n",
    "\n",
    "                self.beta[self.regions[i]] = pd.DataFrame(self.time_FE_layer[i].weights[0].numpy())\n",
    "                self.beta[self.regions[i]].set_index(self.time_periods[self.time_periods_na[self.regions[i]] + 1:], inplace=True)\n",
    "\n",
    "        else:\n",
    "            self.alpha = pd.DataFrame(self.country_FE_layer.weights[0].numpy().T)\n",
    "            self.alpha.columns = self.individuals['global'][1:]\n",
    "\n",
    "            self.beta = pd.DataFrame(self.time_FE_layer.weights[0].numpy())\n",
    "            self.beta.set_index(self.time_periods[self.time_periods_not_na['global']][1:], inplace=True)\n",
    "\n",
    "    def save_params(self, filepath):\n",
    "        \"\"\"\n",
    "        Saving model parameters.\n",
    "\n",
    "         ARGUMENTS\n",
    "            * filepath: string containing path/name of file to be saved.\n",
    "        \"\"\"\n",
    "\n",
    "        self.model.save_weights(filepath)\n",
    "\n",
    "    def in_sample_predictions(self):\n",
    "        \"\"\"\n",
    "        Making in-sample predictions.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        in_sample_preds = self.model(self.inputs)\n",
    "        sigma2_tmp = 0\n",
    "        noObs_tmp = 0\n",
    "        N_agg = 0\n",
    "        country_counter = 0\n",
    "\n",
    "        for region in self.regions:\n",
    "            self.in_sample_pred[region] = self.y_train[region].copy()\n",
    "\n",
    "            if self.formulation == 'national':\n",
    "                for i in range(self.N[region]):\n",
    "                    self.in_sample_pred[region].iloc[:, i] = np.array(in_sample_preds[country_counter][0, :, 0])\n",
    "                    country_counter = country_counter + 1\n",
    "\n",
    "            elif self.formulation == 'regional':\n",
    "                self.in_sample_pred[region].iloc[:, :] = np.array(in_sample_preds[self.regions.index(region)][0, :, :])\n",
    "\n",
    "            else:\n",
    "                self.in_sample_pred[region].iloc[:, :] = np.array(in_sample_preds[0, :, N_agg:N_agg+self.N[region]])\n",
    "                N_agg = N_agg + self.N[region]\n",
    "\n",
    "            if self.regions.index(region) == 0:\n",
    "                in_sample_pred_global = self.in_sample_pred[region]\n",
    "                in_sample_global = self.y_train_df[region]\n",
    "            else:\n",
    "                in_sample_pred_global = pd.concat([in_sample_pred_global, self.in_sample_pred[region]], axis=1)\n",
    "                in_sample_global = pd.concat([in_sample_global, self.y_train_df[region]], axis=1)\n",
    "\n",
    "            mean_tmp = np.nanmean(np.reshape(np.array(self.y_train_df[region]), (-1)))\n",
    "\n",
    "            SSR = np.sum(np.sum((self.y_train_df[region] - self.in_sample_pred[region]) ** 2))\n",
    "            SST = np.sum(np.sum((self.y_train_df[region] - mean_tmp) ** 2))\n",
    "            self.R2[region] = 1 - SSR / SST\n",
    "            self.MSE[region] = SSR / self.noObs[region]\n",
    "\n",
    "            if self.formulation == 'national':\n",
    "                for i in range(self.N[region]):\n",
    "                    SSR = np.sum((self.y_train_df[region].iloc[:, i] - self.in_sample_pred[region].iloc[:, i]) ** 2)\n",
    "                    noObs_tmp = np.sum(~np.isnan(self.y_train_df[region]).iloc[:, i])\n",
    "\n",
    "                    sigma2_tmp = sigma2_tmp + (1 / self.N['global']) * (SSR / noObs_tmp)\n",
    "\n",
    "            elif self.formulation == 'regional':\n",
    "                sigma2_tmp = sigma2_tmp + (1 / self.no_regions) * (SSR / self.noObs[region])\n",
    "                noObs_tmp = noObs_tmp + self.noObs[region]\n",
    "\n",
    "            else:\n",
    "                sigma2_tmp = sigma2_tmp + SSR\n",
    "\n",
    "        mean_tmp = np.nanmean(np.reshape(np.array(in_sample_global), (-1)))\n",
    "\n",
    "        SSR = np.sum(np.sum((in_sample_global - in_sample_pred_global)**2))\n",
    "        SST = np.sum(np.sum((in_sample_global - mean_tmp)**2))\n",
    "        self.R2['global'] = 1 - SSR / SST\n",
    "        self.MSE['global'] = SSR / self.noObs['global']\n",
    "\n",
    "        if self.formulation == 'national':\n",
    "            self.BIC = np.log(sigma2_tmp) + self.m * np.log(self.noObs['global']) / self.noObs['global']\n",
    "\n",
    "        elif self.formulation == 'regional':\n",
    "            self.BIC = np.log(sigma2_tmp) + self.m * np.log(noObs_tmp) / noObs_tmp\n",
    "\n",
    "        else:\n",
    "            self.BIC = np.log(sigma2_tmp) - np.log(self.noObs['global']) + self.m * np.log(self.noObs['global']) / self.noObs['global']\n",
    "\n",
    "    def predict(self, x_test, idx=False):\n",
    "        \"\"\"\n",
    "        Making predictions.\n",
    "\n",
    "        ARGUMENTS\n",
    "            * x_test:  (-1,1) array of input data.\n",
    "            * idx:     Name identifying the country/region to be used for making predictions (if national or regional formulation).\n",
    "\n",
    "\n",
    "        RETURNS\n",
    "            * pred_df: Dataframe containing predictions.\n",
    "        \"\"\"\n",
    "\n",
    "        x_test_tf = tf.convert_to_tensor(np.reshape(x_test, (1, -1, 1)))\n",
    "\n",
    "        if self.formulation in ['national', 'regional']:\n",
    "            pred_np = np.reshape(self.model_pred[idx].predict(x_test_tf), (-1, 1), order='F')\n",
    "\n",
    "        else:\n",
    "            pred_np = np.reshape(self.model_pred.predict(x_test_tf), (-1, 1), order='F')\n",
    "\n",
    "        pred_df = pd.DataFrame(pred_np)\n",
    "        pred_df.set_index(np.reshape(x_test, (-1,)), inplace=True)\n",
    "\n",
    "        return pred_df"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
